{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89a263e4-407c-402e-a616-4638e9417d6e",
   "metadata": {},
   "source": [
    "# 1. Dự đoán điểm số (Ratings Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "022daf9d-00f4-4eb8-a5f6-5a6903bbd3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 3.6399 - mae: 1.5193 - val_loss: 0.9690 - val_mae: 0.7702\n",
      "Epoch 2/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 1.0127 - mae: 0.7782 - val_loss: 0.8616 - val_mae: 0.6960\n",
      "Epoch 3/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.8639 - mae: 0.6998 - val_loss: 0.7669 - val_mae: 0.6691\n",
      "Epoch 4/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7939 - mae: 0.6703 - val_loss: 0.7273 - val_mae: 0.6474\n",
      "Epoch 5/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7263 - mae: 0.6425 - val_loss: 0.6889 - val_mae: 0.6304\n",
      "Epoch 6/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6804 - mae: 0.6220 - val_loss: 0.6312 - val_mae: 0.5814\n",
      "Epoch 7/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6387 - mae: 0.5971 - val_loss: 0.5902 - val_mae: 0.5544\n",
      "Epoch 8/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6223 - mae: 0.5806 - val_loss: 0.5569 - val_mae: 0.5483\n",
      "Epoch 9/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5737 - mae: 0.5718 - val_loss: 0.5329 - val_mae: 0.5147\n",
      "Epoch 10/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5083 - mae: 0.5294 - val_loss: 0.4862 - val_mae: 0.4977\n",
      "Epoch 11/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5641 - mae: 0.5546 - val_loss: 0.4952 - val_mae: 0.4894\n",
      "Epoch 12/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.5256 - mae: 0.5418 - val_loss: 0.4782 - val_mae: 0.5019\n",
      "Epoch 13/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4423 - mae: 0.4948 - val_loss: 0.4488 - val_mae: 0.4849\n",
      "Epoch 14/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4352 - mae: 0.4881 - val_loss: 0.4542 - val_mae: 0.4769\n",
      "Epoch 15/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4541 - mae: 0.5002 - val_loss: 0.4198 - val_mae: 0.4561\n",
      "Epoch 16/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4505 - mae: 0.4978 - val_loss: 0.4779 - val_mae: 0.4760\n",
      "Epoch 17/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4604 - mae: 0.5027 - val_loss: 0.4082 - val_mae: 0.4604\n",
      "Epoch 18/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4345 - mae: 0.4900 - val_loss: 0.4422 - val_mae: 0.4600\n",
      "Epoch 19/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.4337 - mae: 0.4816 - val_loss: 0.4245 - val_mae: 0.4452\n",
      "Epoch 20/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.4152 - mae: 0.4787 - val_loss: 0.3947 - val_mae: 0.4303\n",
      "Epoch 21/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3703 - mae: 0.4393 - val_loss: 0.3836 - val_mae: 0.4296\n",
      "Epoch 22/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3938 - mae: 0.4645 - val_loss: 0.4589 - val_mae: 0.4779\n",
      "Epoch 23/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4026 - mae: 0.4689 - val_loss: 0.4089 - val_mae: 0.4450\n",
      "Epoch 24/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3758 - mae: 0.4545 - val_loss: 0.4214 - val_mae: 0.4649\n",
      "Epoch 25/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3756 - mae: 0.4537 - val_loss: 0.3928 - val_mae: 0.4326\n",
      "Epoch 26/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3345 - mae: 0.4271 - val_loss: 0.4052 - val_mae: 0.4349\n",
      "Epoch 27/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3413 - mae: 0.4280 - val_loss: 0.4273 - val_mae: 0.4434\n",
      "Epoch 28/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3529 - mae: 0.4368 - val_loss: 0.4162 - val_mae: 0.4478\n",
      "Epoch 29/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3367 - mae: 0.4264 - val_loss: 0.3954 - val_mae: 0.4323\n",
      "Epoch 30/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3435 - mae: 0.4228 - val_loss: 0.3835 - val_mae: 0.4181\n",
      "Epoch 31/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3171 - mae: 0.4169 - val_loss: 0.3783 - val_mae: 0.4146\n",
      "Epoch 32/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3610 - mae: 0.4389 - val_loss: 0.4177 - val_mae: 0.4391\n",
      "Epoch 33/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3321 - mae: 0.4259 - val_loss: 0.3682 - val_mae: 0.4097\n",
      "Epoch 34/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3222 - mae: 0.4107 - val_loss: 0.3699 - val_mae: 0.4155\n",
      "Epoch 35/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.3171 - mae: 0.4138 - val_loss: 0.3525 - val_mae: 0.4085\n",
      "Epoch 36/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2961 - mae: 0.4041 - val_loss: 0.3649 - val_mae: 0.4099\n",
      "Epoch 37/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3255 - mae: 0.4092 - val_loss: 0.3692 - val_mae: 0.4153\n",
      "Epoch 38/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3058 - mae: 0.4069 - val_loss: 0.3456 - val_mae: 0.4022\n",
      "Epoch 39/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3018 - mae: 0.4052 - val_loss: 0.3780 - val_mae: 0.4240\n",
      "Epoch 40/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3216 - mae: 0.4150 - val_loss: 0.3651 - val_mae: 0.4028\n",
      "Epoch 41/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2800 - mae: 0.3821 - val_loss: 0.3487 - val_mae: 0.4032\n",
      "Epoch 42/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2797 - mae: 0.3814 - val_loss: 0.3413 - val_mae: 0.4016\n",
      "Epoch 43/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2883 - mae: 0.3918 - val_loss: 0.3424 - val_mae: 0.3955\n",
      "Epoch 44/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2810 - mae: 0.3884 - val_loss: 0.3810 - val_mae: 0.4132\n",
      "Epoch 45/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3021 - mae: 0.4016 - val_loss: 0.3495 - val_mae: 0.4010\n",
      "Epoch 46/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2674 - mae: 0.3779 - val_loss: 0.3461 - val_mae: 0.4032\n",
      "Epoch 47/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2823 - mae: 0.3885 - val_loss: 0.3611 - val_mae: 0.4133\n",
      "Epoch 48/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2730 - mae: 0.3814 - val_loss: 0.3917 - val_mae: 0.4209\n",
      "Epoch 49/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2758 - mae: 0.3843 - val_loss: 0.3507 - val_mae: 0.4013\n",
      "Epoch 50/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2887 - mae: 0.3935 - val_loss: 0.3267 - val_mae: 0.3992\n",
      "Epoch 51/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2735 - mae: 0.3878 - val_loss: 0.3580 - val_mae: 0.4244\n",
      "Epoch 52/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2863 - mae: 0.3915 - val_loss: 0.3567 - val_mae: 0.4018\n",
      "Epoch 53/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2680 - mae: 0.3812 - val_loss: 0.3605 - val_mae: 0.3954\n",
      "Epoch 54/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2758 - mae: 0.3821 - val_loss: 0.3534 - val_mae: 0.4112\n",
      "Epoch 55/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2765 - mae: 0.3806 - val_loss: 0.3598 - val_mae: 0.4080\n",
      "Epoch 56/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2634 - mae: 0.3769 - val_loss: 0.3574 - val_mae: 0.4064\n",
      "Epoch 57/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2652 - mae: 0.3753 - val_loss: 0.3647 - val_mae: 0.4040\n",
      "Epoch 58/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2766 - mae: 0.3828 - val_loss: 0.3410 - val_mae: 0.4000\n",
      "Epoch 59/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2666 - mae: 0.3762 - val_loss: 0.3901 - val_mae: 0.4168\n",
      "Epoch 60/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2739 - mae: 0.3802 - val_loss: 0.3510 - val_mae: 0.4072\n",
      "Epoch 61/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2512 - mae: 0.3583 - val_loss: 0.3440 - val_mae: 0.3984\n",
      "Epoch 62/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2603 - mae: 0.3748 - val_loss: 0.3530 - val_mae: 0.3959\n",
      "Epoch 63/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2630 - mae: 0.3733 - val_loss: 0.3325 - val_mae: 0.4130\n",
      "Epoch 64/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2502 - mae: 0.3698 - val_loss: 0.3402 - val_mae: 0.3952\n",
      "Epoch 65/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2591 - mae: 0.3658 - val_loss: 0.3226 - val_mae: 0.3830\n",
      "Epoch 66/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2703 - mae: 0.3702 - val_loss: 0.3481 - val_mae: 0.4005\n",
      "Epoch 67/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2595 - mae: 0.3668 - val_loss: 0.3679 - val_mae: 0.4191\n",
      "Epoch 68/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2641 - mae: 0.3768 - val_loss: 0.3389 - val_mae: 0.3992\n",
      "Epoch 69/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2474 - mae: 0.3601 - val_loss: 0.3527 - val_mae: 0.4095\n",
      "Epoch 70/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2680 - mae: 0.3785 - val_loss: 0.3340 - val_mae: 0.4058\n",
      "Epoch 71/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2409 - mae: 0.3576 - val_loss: 0.3104 - val_mae: 0.3905\n",
      "Epoch 72/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2444 - mae: 0.3666 - val_loss: 0.3489 - val_mae: 0.4022\n",
      "Epoch 73/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2562 - mae: 0.3702 - val_loss: 0.3393 - val_mae: 0.3953\n",
      "Epoch 74/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2542 - mae: 0.3688 - val_loss: 0.3382 - val_mae: 0.3980\n",
      "Epoch 75/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2451 - mae: 0.3607 - val_loss: 0.3334 - val_mae: 0.3993\n",
      "Epoch 76/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2495 - mae: 0.3657 - val_loss: 0.3366 - val_mae: 0.4013\n",
      "Epoch 77/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2367 - mae: 0.3561 - val_loss: 0.3414 - val_mae: 0.3993\n",
      "Epoch 78/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2303 - mae: 0.3536 - val_loss: 0.3449 - val_mae: 0.4010\n",
      "Epoch 79/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2301 - mae: 0.3479 - val_loss: 0.3278 - val_mae: 0.3932\n",
      "Epoch 80/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2376 - mae: 0.3548 - val_loss: 0.3534 - val_mae: 0.3937\n",
      "Epoch 81/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2319 - mae: 0.3486 - val_loss: 0.3356 - val_mae: 0.3947\n",
      "Epoch 82/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2432 - mae: 0.3584 - val_loss: 0.3408 - val_mae: 0.3935\n",
      "Epoch 83/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2417 - mae: 0.3538 - val_loss: 0.3296 - val_mae: 0.3889\n",
      "Epoch 84/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2344 - mae: 0.3490 - val_loss: 0.3204 - val_mae: 0.3899\n",
      "Epoch 85/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2176 - mae: 0.3410 - val_loss: 0.3459 - val_mae: 0.4032\n",
      "Epoch 86/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2191 - mae: 0.3432 - val_loss: 0.3290 - val_mae: 0.3993\n",
      "Epoch 87/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2332 - mae: 0.3468 - val_loss: 0.3315 - val_mae: 0.3997\n",
      "Epoch 88/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2370 - mae: 0.3526 - val_loss: 0.3453 - val_mae: 0.3971\n",
      "Epoch 89/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2329 - mae: 0.3457 - val_loss: 0.3311 - val_mae: 0.3976\n",
      "Epoch 90/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2346 - mae: 0.3480 - val_loss: 0.3313 - val_mae: 0.3946\n",
      "Epoch 91/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2300 - mae: 0.3404 - val_loss: 0.3483 - val_mae: 0.4117\n",
      "Epoch 92/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2344 - mae: 0.3571 - val_loss: 0.3482 - val_mae: 0.4003\n",
      "Epoch 93/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.2280 - mae: 0.3408 - val_loss: 0.3358 - val_mae: 0.3983\n",
      "Epoch 94/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2317 - mae: 0.3530 - val_loss: 0.3232 - val_mae: 0.3998\n",
      "Epoch 95/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2105 - mae: 0.3281 - val_loss: 0.3506 - val_mae: 0.3980\n",
      "Epoch 96/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2351 - mae: 0.3499 - val_loss: 0.3546 - val_mae: 0.4018\n",
      "Epoch 97/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2180 - mae: 0.3385 - val_loss: 0.3456 - val_mae: 0.4041\n",
      "Epoch 98/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2234 - mae: 0.3432 - val_loss: 0.3456 - val_mae: 0.4024\n",
      "Epoch 99/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2265 - mae: 0.3428 - val_loss: 0.3203 - val_mae: 0.3858\n",
      "Epoch 100/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2140 - mae: 0.3348 - val_loss: 0.3471 - val_mae: 0.3969\n",
      "Epoch 101/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2235 - mae: 0.3391 - val_loss: 0.3411 - val_mae: 0.3977\n",
      "Epoch 102/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2191 - mae: 0.3366 - val_loss: 0.3384 - val_mae: 0.3888\n",
      "Epoch 103/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2110 - mae: 0.3279 - val_loss: 0.3541 - val_mae: 0.4044\n",
      "Epoch 104/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2248 - mae: 0.3450 - val_loss: 0.3351 - val_mae: 0.4074\n",
      "Epoch 105/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2292 - mae: 0.3465 - val_loss: 0.3188 - val_mae: 0.3868\n",
      "Epoch 106/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2301 - mae: 0.3479 - val_loss: 0.3184 - val_mae: 0.3895\n",
      "Epoch 107/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2209 - mae: 0.3372 - val_loss: 0.3536 - val_mae: 0.4095\n",
      "Epoch 108/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2282 - mae: 0.3438 - val_loss: 0.3272 - val_mae: 0.3931\n",
      "Epoch 109/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2321 - mae: 0.3472 - val_loss: 0.3177 - val_mae: 0.3953\n",
      "Epoch 110/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2160 - mae: 0.3390 - val_loss: 0.3448 - val_mae: 0.3902\n",
      "Epoch 111/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2153 - mae: 0.3310 - val_loss: 0.3304 - val_mae: 0.3894\n",
      "Epoch 112/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2076 - mae: 0.3320 - val_loss: 0.3294 - val_mae: 0.3941\n",
      "Epoch 113/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2097 - mae: 0.3322 - val_loss: 0.3449 - val_mae: 0.3983\n",
      "Epoch 114/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2145 - mae: 0.3399 - val_loss: 0.3458 - val_mae: 0.3935\n",
      "Epoch 115/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.2032 - mae: 0.3233 - val_loss: 0.3376 - val_mae: 0.4004\n",
      "Epoch 116/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2188 - mae: 0.3398 - val_loss: 0.3340 - val_mae: 0.3940\n",
      "Epoch 117/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2123 - mae: 0.3304 - val_loss: 0.3229 - val_mae: 0.3917\n",
      "Epoch 118/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2224 - mae: 0.3362 - val_loss: 0.3245 - val_mae: 0.3889\n",
      "Epoch 119/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2122 - mae: 0.3304 - val_loss: 0.3169 - val_mae: 0.3904\n",
      "Epoch 120/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2071 - mae: 0.3204 - val_loss: 0.3324 - val_mae: 0.3870\n",
      "Epoch 121/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2126 - mae: 0.3357 - val_loss: 0.3288 - val_mae: 0.3861\n",
      "Epoch 122/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2102 - mae: 0.3257 - val_loss: 0.3380 - val_mae: 0.3936\n",
      "Epoch 123/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1948 - mae: 0.3116 - val_loss: 0.3180 - val_mae: 0.3959\n",
      "Epoch 124/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2142 - mae: 0.3304 - val_loss: 0.3472 - val_mae: 0.4007\n",
      "Epoch 125/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2025 - mae: 0.3231 - val_loss: 0.3256 - val_mae: 0.3941\n",
      "Epoch 126/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2104 - mae: 0.3289 - val_loss: 0.3268 - val_mae: 0.3926\n",
      "Epoch 127/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2012 - mae: 0.3195 - val_loss: 0.3255 - val_mae: 0.3896\n",
      "Epoch 128/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2115 - mae: 0.3301 - val_loss: 0.3157 - val_mae: 0.3914\n",
      "Epoch 129/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2088 - mae: 0.3283 - val_loss: 0.3255 - val_mae: 0.3972\n",
      "Epoch 130/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2172 - mae: 0.3309 - val_loss: 0.3203 - val_mae: 0.3965\n",
      "Epoch 131/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1976 - mae: 0.3210 - val_loss: 0.3098 - val_mae: 0.3808\n",
      "Epoch 132/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2069 - mae: 0.3330 - val_loss: 0.3275 - val_mae: 0.3920\n",
      "Epoch 133/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2018 - mae: 0.3271 - val_loss: 0.3226 - val_mae: 0.3897\n",
      "Epoch 134/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1921 - mae: 0.3130 - val_loss: 0.3261 - val_mae: 0.3932\n",
      "Epoch 135/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1925 - mae: 0.3133 - val_loss: 0.3154 - val_mae: 0.3910\n",
      "Epoch 136/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1972 - mae: 0.3184 - val_loss: 0.3418 - val_mae: 0.4096\n",
      "Epoch 137/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1968 - mae: 0.3180 - val_loss: 0.3246 - val_mae: 0.3920\n",
      "Epoch 138/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2006 - mae: 0.3198 - val_loss: 0.3191 - val_mae: 0.3904\n",
      "Epoch 139/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2044 - mae: 0.3284 - val_loss: 0.3423 - val_mae: 0.4031\n",
      "Epoch 140/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2017 - mae: 0.3219 - val_loss: 0.3307 - val_mae: 0.3940\n",
      "Epoch 141/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2011 - mae: 0.3238 - val_loss: 0.3303 - val_mae: 0.4069\n",
      "Epoch 142/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2055 - mae: 0.3265 - val_loss: 0.3190 - val_mae: 0.3881\n",
      "Epoch 143/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.2036 - mae: 0.3190 - val_loss: 0.3196 - val_mae: 0.3933\n",
      "Epoch 144/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1962 - mae: 0.3176 - val_loss: 0.3374 - val_mae: 0.3952\n",
      "Epoch 145/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2034 - mae: 0.3237 - val_loss: 0.3206 - val_mae: 0.3885\n",
      "Epoch 146/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1972 - mae: 0.3152 - val_loss: 0.3198 - val_mae: 0.3879\n",
      "Epoch 147/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1960 - mae: 0.3138 - val_loss: 0.3241 - val_mae: 0.3957\n",
      "Epoch 148/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1948 - mae: 0.3212 - val_loss: 0.3106 - val_mae: 0.3870\n",
      "Epoch 149/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1849 - mae: 0.3080 - val_loss: 0.3354 - val_mae: 0.3972\n",
      "Epoch 150/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2146 - mae: 0.3250 - val_loss: 0.3410 - val_mae: 0.4007\n",
      "Epoch 151/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1942 - mae: 0.3204 - val_loss: 0.3230 - val_mae: 0.3886\n",
      "Epoch 152/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1856 - mae: 0.3090 - val_loss: 0.3405 - val_mae: 0.4024\n",
      "Epoch 153/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1972 - mae: 0.3235 - val_loss: 0.3394 - val_mae: 0.4005\n",
      "Epoch 154/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1907 - mae: 0.3109 - val_loss: 0.3316 - val_mae: 0.3922\n",
      "Epoch 155/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1734 - mae: 0.2961 - val_loss: 0.3223 - val_mae: 0.3982\n",
      "Epoch 156/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1791 - mae: 0.3024 - val_loss: 0.3360 - val_mae: 0.4039\n",
      "Epoch 157/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1879 - mae: 0.3141 - val_loss: 0.3113 - val_mae: 0.3894\n",
      "Epoch 158/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1981 - mae: 0.3235 - val_loss: 0.3233 - val_mae: 0.3950\n",
      "Epoch 159/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1921 - mae: 0.3103 - val_loss: 0.3242 - val_mae: 0.3905\n",
      "Epoch 160/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1963 - mae: 0.3137 - val_loss: 0.3234 - val_mae: 0.3927\n",
      "Epoch 161/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1851 - mae: 0.3050 - val_loss: 0.3222 - val_mae: 0.3853\n",
      "Epoch 162/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1857 - mae: 0.3077 - val_loss: 0.3433 - val_mae: 0.4058\n",
      "Epoch 163/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1860 - mae: 0.3081 - val_loss: 0.3056 - val_mae: 0.3822\n",
      "Epoch 164/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1801 - mae: 0.3020 - val_loss: 0.3207 - val_mae: 0.3904\n",
      "Epoch 165/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1937 - mae: 0.3171 - val_loss: 0.3401 - val_mae: 0.4041\n",
      "Epoch 166/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1870 - mae: 0.3079 - val_loss: 0.3300 - val_mae: 0.3856\n",
      "Epoch 167/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1803 - mae: 0.3028 - val_loss: 0.3272 - val_mae: 0.3911\n",
      "Epoch 168/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1841 - mae: 0.3043 - val_loss: 0.3233 - val_mae: 0.3933\n",
      "Epoch 169/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1803 - mae: 0.3018 - val_loss: 0.3314 - val_mae: 0.3906\n",
      "Epoch 170/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1895 - mae: 0.3097 - val_loss: 0.3327 - val_mae: 0.3917\n",
      "Epoch 171/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1933 - mae: 0.3111 - val_loss: 0.3383 - val_mae: 0.4024\n",
      "Epoch 172/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1894 - mae: 0.3117 - val_loss: 0.3327 - val_mae: 0.3953\n",
      "Epoch 173/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1796 - mae: 0.3004 - val_loss: 0.3220 - val_mae: 0.3870\n",
      "Epoch 174/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1811 - mae: 0.3032 - val_loss: 0.3239 - val_mae: 0.3937\n",
      "Epoch 175/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1768 - mae: 0.2958 - val_loss: 0.3543 - val_mae: 0.4065\n",
      "Epoch 176/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1869 - mae: 0.3096 - val_loss: 0.3255 - val_mae: 0.3927\n",
      "Epoch 177/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1940 - mae: 0.3171 - val_loss: 0.3269 - val_mae: 0.3903\n",
      "Epoch 178/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1864 - mae: 0.3088 - val_loss: 0.3312 - val_mae: 0.3956\n",
      "Epoch 179/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1809 - mae: 0.3046 - val_loss: 0.3274 - val_mae: 0.3997\n",
      "Epoch 180/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1838 - mae: 0.3036 - val_loss: 0.3252 - val_mae: 0.3879\n",
      "Epoch 181/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1764 - mae: 0.2977 - val_loss: 0.3233 - val_mae: 0.3908\n",
      "Epoch 182/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1787 - mae: 0.3014 - val_loss: 0.3547 - val_mae: 0.4040\n",
      "Epoch 183/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1923 - mae: 0.3157 - val_loss: 0.3364 - val_mae: 0.3965\n",
      "Epoch 184/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1856 - mae: 0.3129 - val_loss: 0.3418 - val_mae: 0.4015\n",
      "Epoch 185/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1818 - mae: 0.3065 - val_loss: 0.3456 - val_mae: 0.3987\n",
      "Epoch 186/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1764 - mae: 0.2967 - val_loss: 0.3465 - val_mae: 0.4034\n",
      "Epoch 187/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1915 - mae: 0.3115 - val_loss: 0.3314 - val_mae: 0.4048\n",
      "Epoch 188/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1810 - mae: 0.2995 - val_loss: 0.3271 - val_mae: 0.3962\n",
      "Epoch 189/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1839 - mae: 0.3041 - val_loss: 0.3411 - val_mae: 0.4006\n",
      "Epoch 190/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1817 - mae: 0.3022 - val_loss: 0.3188 - val_mae: 0.3915\n",
      "Epoch 191/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1756 - mae: 0.2988 - val_loss: 0.3345 - val_mae: 0.4004\n",
      "Epoch 192/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1877 - mae: 0.3135 - val_loss: 0.3584 - val_mae: 0.4149\n",
      "Epoch 193/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1703 - mae: 0.2938 - val_loss: 0.3180 - val_mae: 0.3866\n",
      "Epoch 194/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1655 - mae: 0.2919 - val_loss: 0.3656 - val_mae: 0.4063\n",
      "Epoch 195/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1960 - mae: 0.3148 - val_loss: 0.3342 - val_mae: 0.3931\n",
      "Epoch 196/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1760 - mae: 0.3034 - val_loss: 0.3544 - val_mae: 0.3959\n",
      "Epoch 197/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.1679 - mae: 0.2917 - val_loss: 0.3420 - val_mae: 0.3930\n",
      "Epoch 198/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1836 - mae: 0.3078 - val_loss: 0.3343 - val_mae: 0.3991\n",
      "Epoch 199/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1862 - mae: 0.3033 - val_loss: 0.3399 - val_mae: 0.3914\n",
      "Epoch 200/200\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1736 - mae: 0.2901 - val_loss: 0.3445 - val_mae: 0.4024\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3776 - mae: 0.4143\n",
      "Test Loss: 0.3650, Test MAE: 0.4044\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, callbacks\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Đọc dữ liệu\n",
    "data = pd.read_csv('cleaned_hospitals.csv')\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "X = data.drop(columns=['Rating_Overall'])\n",
    "y = data['Rating_Overall']\n",
    "\n",
    "# Đảm bảo tất cả các giá trị là số\n",
    "X = X.apply(pd.to_numeric, errors='coerce').fillna(0)\n",
    "y = pd.to_numeric(y, errors='coerce').fillna(0)\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Xây dựng mô hình\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),  # Định nghĩa hình dạng đầu vào\n",
    "    layers.Dense(128, activation='relu'),       # Tăng số lượng nơ-ron\n",
    "    layers.Dropout(0.2),                        # Thêm lớp Dropout để giảm thiểu overfitting\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # Đầu ra là một số thực\n",
    "])\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),  # Điều chỉnh learning rate\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mae'])  # Thêm metric MAE để theo dõi trong quá trình huấn luyện\n",
    "\n",
    "# Thêm callback để lưu mô hình tốt nhất\n",
    "model_checkpoint = callbacks.ModelCheckpoint(\n",
    "    'best_rating_model.keras',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=32, validation_split=0.2,\n",
    "                    callbacks=[model_checkpoint], verbose=1)\n",
    "\n",
    "# Đánh giá mô hình\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test MAE: {mae:.4f}')\n",
    "\n",
    "# Lưu mô hình cuối cùng\n",
    "model.save('final_rating_prediction.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53534939-917c-4b99-904c-f39fbc707d6d",
   "metadata": {},
   "source": [
    "# 2. Phân loại (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e7856ff-6240-4d38-8a8e-4233a31bc2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.7230 - loss: 0.6885 - val_accuracy: 0.7134 - val_loss: 0.6757\n",
      "Epoch 2/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7070 - loss: 0.6726 - val_accuracy: 0.7134 - val_loss: 0.6608\n",
      "Epoch 3/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7088 - loss: 0.6586 - val_accuracy: 0.7134 - val_loss: 0.6484\n",
      "Epoch 4/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7048 - loss: 0.6477 - val_accuracy: 0.7134 - val_loss: 0.6380\n",
      "Epoch 5/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7174 - loss: 0.6344 - val_accuracy: 0.7134 - val_loss: 0.6296\n",
      "Epoch 6/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7121 - loss: 0.6283 - val_accuracy: 0.7134 - val_loss: 0.6229\n",
      "Epoch 7/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7060 - loss: 0.6249 - val_accuracy: 0.7134 - val_loss: 0.6175\n",
      "Epoch 8/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7072 - loss: 0.6194 - val_accuracy: 0.7134 - val_loss: 0.6131\n",
      "Epoch 9/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7048 - loss: 0.6170 - val_accuracy: 0.7134 - val_loss: 0.6097\n",
      "Epoch 10/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6999 - loss: 0.6172 - val_accuracy: 0.7134 - val_loss: 0.6071\n",
      "Epoch 11/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6978 - loss: 0.6165 - val_accuracy: 0.7134 - val_loss: 0.6051\n",
      "Epoch 12/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7093 - loss: 0.6074 - val_accuracy: 0.7134 - val_loss: 0.6035\n",
      "Epoch 13/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7106 - loss: 0.6052 - val_accuracy: 0.7134 - val_loss: 0.6024\n",
      "Epoch 14/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7081 - loss: 0.6060 - val_accuracy: 0.7134 - val_loss: 0.6015\n",
      "Epoch 15/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7066 - loss: 0.6065 - val_accuracy: 0.7134 - val_loss: 0.6009\n",
      "Epoch 16/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7184 - loss: 0.5967 - val_accuracy: 0.7134 - val_loss: 0.6004\n",
      "Epoch 17/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7023 - loss: 0.6093 - val_accuracy: 0.7134 - val_loss: 0.6001\n",
      "Epoch 18/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7116 - loss: 0.6015 - val_accuracy: 0.7134 - val_loss: 0.5998\n",
      "Epoch 19/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7212 - loss: 0.5932 - val_accuracy: 0.7134 - val_loss: 0.5996\n",
      "Epoch 20/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7120 - loss: 0.6007 - val_accuracy: 0.7134 - val_loss: 0.5995\n",
      "Epoch 21/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7013 - loss: 0.6097 - val_accuracy: 0.7134 - val_loss: 0.5994\n",
      "Epoch 22/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6958 - loss: 0.6145 - val_accuracy: 0.7134 - val_loss: 0.5993\n",
      "Epoch 23/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7146 - loss: 0.5982 - val_accuracy: 0.7134 - val_loss: 0.5993\n",
      "Epoch 24/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7081 - loss: 0.6039 - val_accuracy: 0.7134 - val_loss: 0.5992\n",
      "Epoch 25/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7119 - loss: 0.6005 - val_accuracy: 0.7134 - val_loss: 0.5992\n",
      "Epoch 26/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7083 - loss: 0.6036 - val_accuracy: 0.7134 - val_loss: 0.5992\n",
      "Epoch 27/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7183 - loss: 0.5948 - val_accuracy: 0.7134 - val_loss: 0.5992\n",
      "Epoch 28/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7180 - loss: 0.5950 - val_accuracy: 0.7134 - val_loss: 0.5992\n",
      "Epoch 29/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7021 - loss: 0.6092 - val_accuracy: 0.7134 - val_loss: 0.5992\n",
      "Epoch 30/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7236 - loss: 0.5901 - val_accuracy: 0.7134 - val_loss: 0.5992\n",
      "Epoch 31/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7185 - loss: 0.5945 - val_accuracy: 0.7134 - val_loss: 0.5992\n",
      "Epoch 32/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6938 - loss: 0.6166 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 33/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7020 - loss: 0.6094 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 34/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7153 - loss: 0.5974 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 35/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7086 - loss: 0.6035 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 36/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7173 - loss: 0.5956 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 37/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7220 - loss: 0.5914 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 38/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7093 - loss: 0.6028 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 39/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7216 - loss: 0.5917 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 40/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7157 - loss: 0.5970 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 41/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7131 - loss: 0.5994 - val_accuracy: 0.7134 - val_loss: 0.5992\n",
      "Epoch 42/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7099 - loss: 0.6022 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 43/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6997 - loss: 0.6114 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 44/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7203 - loss: 0.5930 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 45/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7260 - loss: 0.5878 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 46/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7031 - loss: 0.6084 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 47/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7115 - loss: 0.6008 - val_accuracy: 0.7134 - val_loss: 0.5992\n",
      "Epoch 48/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7125 - loss: 0.6000 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 49/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7038 - loss: 0.6077 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 50/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7018 - loss: 0.6095 - val_accuracy: 0.7134 - val_loss: 0.5992\n",
      "Epoch 51/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7176 - loss: 0.5953 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 52/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7094 - loss: 0.6027 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 53/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7054 - loss: 0.6063 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 54/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7275 - loss: 0.5864 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 55/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7003 - loss: 0.6109 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 56/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7148 - loss: 0.5978 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 57/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7030 - loss: 0.6084 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 58/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7062 - loss: 0.6056 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 59/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7137 - loss: 0.5988 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 60/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7101 - loss: 0.6021 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 61/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6990 - loss: 0.6121 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 62/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7087 - loss: 0.6034 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 63/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7114 - loss: 0.6009 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "Epoch 64/150\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7053 - loss: 0.6064 - val_accuracy: 0.7134 - val_loss: 0.5991\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7144 - loss: 0.5982\n",
      "Model Loss: 0.6022, Model Accuracy: 0.7099\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Đọc dữ liệu\n",
    "data = pd.read_csv('cleaned_hospitals.csv')\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "X = data.drop(columns=['Rating_Overall'])\n",
    "y = (data['Rating_Overall'] > 3).astype(int)  # Phân loại tốt (1) và kém (0)\n",
    "\n",
    "# Chuyển đổi dữ liệu sang kiểu số (numeric) và xử lý giá trị thiếu\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "X.fillna(X.mean(), inplace=True)  # Thay thế NaN bằng giá trị trung bình của từng cột\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Xây dựng mô hình\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),  # Lớp đầu vào\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.3),  # Thêm Dropout để giảm overfitting\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.3),  # Thêm Dropout\n",
    "    layers.Dense(1, activation='sigmoid')  # Đầu ra nhị phân\n",
    "])\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Cài đặt EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Đánh giá mô hình\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Model Loss: {loss:.4f}, Model Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('classification_model.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354c73ab-4d4c-4299-ad06-d9eea871f559",
   "metadata": {},
   "source": [
    "# 3. Nhận dạng mẫu (Pattern Recognition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72c4aede-9d92-4f0a-98ec-835a7bacaa84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 1.2205 - mean_absolute_error: 0.8350 - val_loss: 0.4347 - val_mean_absolute_error: 0.5077\n",
      "Epoch 2/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.3843 - mean_absolute_error: 0.4724 - val_loss: 0.4664 - val_mean_absolute_error: 0.5407\n",
      "Epoch 3/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.2096 - mean_absolute_error: 0.3343 - val_loss: 0.4659 - val_mean_absolute_error: 0.5155\n",
      "Epoch 4/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0717 - mean_absolute_error: 0.1869 - val_loss: 0.5039 - val_mean_absolute_error: 0.5675\n",
      "Epoch 5/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0465 - mean_absolute_error: 0.1526 - val_loss: 0.4399 - val_mean_absolute_error: 0.5059\n",
      "Epoch 6/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0236 - mean_absolute_error: 0.1062 - val_loss: 0.4255 - val_mean_absolute_error: 0.4953\n",
      "Epoch 7/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0129 - mean_absolute_error: 0.0801 - val_loss: 0.4485 - val_mean_absolute_error: 0.5154\n",
      "Epoch 8/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0083 - mean_absolute_error: 0.0622 - val_loss: 0.4365 - val_mean_absolute_error: 0.5047\n",
      "Epoch 9/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0054 - mean_absolute_error: 0.0497 - val_loss: 0.4370 - val_mean_absolute_error: 0.5048\n",
      "Epoch 10/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0044 - mean_absolute_error: 0.0449 - val_loss: 0.4417 - val_mean_absolute_error: 0.5095\n",
      "Epoch 11/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0043 - mean_absolute_error: 0.0438 - val_loss: 0.4400 - val_mean_absolute_error: 0.5123\n",
      "Epoch 12/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - loss: 0.0042 - mean_absolute_error: 0.0444 - val_loss: 0.4314 - val_mean_absolute_error: 0.5028\n",
      "Epoch 13/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0042 - mean_absolute_error: 0.0441 - val_loss: 0.4449 - val_mean_absolute_error: 0.5157\n",
      "Epoch 14/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0046 - mean_absolute_error: 0.0458 - val_loss: 0.4368 - val_mean_absolute_error: 0.5081\n",
      "Epoch 15/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0049 - mean_absolute_error: 0.0474 - val_loss: 0.4453 - val_mean_absolute_error: 0.5151\n",
      "Epoch 16/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0055 - mean_absolute_error: 0.0505 - val_loss: 0.4341 - val_mean_absolute_error: 0.5065\n",
      "Epoch 17/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0061 - mean_absolute_error: 0.0534 - val_loss: 0.4414 - val_mean_absolute_error: 0.5098\n",
      "Epoch 18/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0056 - mean_absolute_error: 0.0515 - val_loss: 0.4334 - val_mean_absolute_error: 0.5038\n",
      "Epoch 19/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0055 - mean_absolute_error: 0.0513 - val_loss: 0.4366 - val_mean_absolute_error: 0.5021\n",
      "Epoch 20/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0064 - mean_absolute_error: 0.0541 - val_loss: 0.4304 - val_mean_absolute_error: 0.4978\n",
      "Epoch 21/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0059 - mean_absolute_error: 0.0525 - val_loss: 0.4356 - val_mean_absolute_error: 0.5013\n",
      "Epoch 22/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0055 - mean_absolute_error: 0.0491 - val_loss: 0.4466 - val_mean_absolute_error: 0.5110\n",
      "Epoch 23/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0054 - mean_absolute_error: 0.0486 - val_loss: 0.4313 - val_mean_absolute_error: 0.4946\n",
      "Epoch 24/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0054 - mean_absolute_error: 0.0488 - val_loss: 0.4399 - val_mean_absolute_error: 0.5062\n",
      "Epoch 25/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0045 - mean_absolute_error: 0.0439 - val_loss: 0.4496 - val_mean_absolute_error: 0.5142\n",
      "Epoch 26/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0040 - mean_absolute_error: 0.0414 - val_loss: 0.4306 - val_mean_absolute_error: 0.4951\n",
      "Epoch 27/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0033 - mean_absolute_error: 0.0379 - val_loss: 0.4485 - val_mean_absolute_error: 0.5135\n",
      "Epoch 28/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0030 - mean_absolute_error: 0.0365 - val_loss: 0.4544 - val_mean_absolute_error: 0.5204\n",
      "Epoch 29/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0024 - mean_absolute_error: 0.0330 - val_loss: 0.4476 - val_mean_absolute_error: 0.5131\n",
      "Epoch 30/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0019 - mean_absolute_error: 0.0282 - val_loss: 0.4450 - val_mean_absolute_error: 0.5103\n",
      "Epoch 31/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0028 - mean_absolute_error: 0.0349 - val_loss: 0.4384 - val_mean_absolute_error: 0.5045\n",
      "Epoch 32/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0037 - mean_absolute_error: 0.0410 - val_loss: 0.4658 - val_mean_absolute_error: 0.5291\n",
      "Epoch 33/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0049 - mean_absolute_error: 0.0452 - val_loss: 0.4411 - val_mean_absolute_error: 0.5057\n",
      "Epoch 34/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0053 - mean_absolute_error: 0.0495 - val_loss: 0.4365 - val_mean_absolute_error: 0.5004\n",
      "Epoch 35/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0054 - mean_absolute_error: 0.0510 - val_loss: 0.4437 - val_mean_absolute_error: 0.5031\n",
      "Epoch 36/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0046 - mean_absolute_error: 0.0464 - val_loss: 0.4442 - val_mean_absolute_error: 0.5000\n",
      "Epoch 37/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0041 - mean_absolute_error: 0.0417 - val_loss: 0.4406 - val_mean_absolute_error: 0.5004\n",
      "Epoch 38/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0039 - mean_absolute_error: 0.0413 - val_loss: 0.4551 - val_mean_absolute_error: 0.5164\n",
      "Epoch 39/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0037 - mean_absolute_error: 0.0415 - val_loss: 0.4416 - val_mean_absolute_error: 0.4957\n",
      "Epoch 40/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0049 - mean_absolute_error: 0.0458 - val_loss: 0.4490 - val_mean_absolute_error: 0.5002\n",
      "Epoch 41/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0044 - mean_absolute_error: 0.0428 - val_loss: 0.4468 - val_mean_absolute_error: 0.5020\n",
      "Epoch 42/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0030 - mean_absolute_error: 0.0381 - val_loss: 0.4315 - val_mean_absolute_error: 0.4907\n",
      "Epoch 43/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0023 - mean_absolute_error: 0.0325 - val_loss: 0.4421 - val_mean_absolute_error: 0.4975\n",
      "Epoch 44/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0021 - mean_absolute_error: 0.0302 - val_loss: 0.4424 - val_mean_absolute_error: 0.4961\n",
      "Epoch 45/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0018 - mean_absolute_error: 0.0271 - val_loss: 0.4481 - val_mean_absolute_error: 0.5040\n",
      "Epoch 46/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0017 - mean_absolute_error: 0.0267 - val_loss: 0.4589 - val_mean_absolute_error: 0.5142\n",
      "Epoch 47/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0020 - mean_absolute_error: 0.0285 - val_loss: 0.4532 - val_mean_absolute_error: 0.5081\n",
      "Epoch 48/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0019 - mean_absolute_error: 0.0291 - val_loss: 0.4575 - val_mean_absolute_error: 0.5001\n",
      "Epoch 49/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0022 - mean_absolute_error: 0.0315 - val_loss: 0.4551 - val_mean_absolute_error: 0.4967\n",
      "Epoch 50/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0030 - mean_absolute_error: 0.0355 - val_loss: 0.4416 - val_mean_absolute_error: 0.4862\n",
      "Epoch 51/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0036 - mean_absolute_error: 0.0395 - val_loss: 0.4541 - val_mean_absolute_error: 0.4906\n",
      "Epoch 52/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0047 - mean_absolute_error: 0.0447 - val_loss: 0.4433 - val_mean_absolute_error: 0.4891\n",
      "Epoch 53/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0039 - mean_absolute_error: 0.0416 - val_loss: 0.4832 - val_mean_absolute_error: 0.5227\n",
      "Epoch 54/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0035 - mean_absolute_error: 0.0397 - val_loss: 0.4524 - val_mean_absolute_error: 0.4875\n",
      "Epoch 55/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0023 - mean_absolute_error: 0.0324 - val_loss: 0.4453 - val_mean_absolute_error: 0.4977\n",
      "Epoch 56/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0025 - mean_absolute_error: 0.0323 - val_loss: 0.4574 - val_mean_absolute_error: 0.4803\n",
      "Epoch 57/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0028 - mean_absolute_error: 0.0334 - val_loss: 0.4665 - val_mean_absolute_error: 0.4825\n",
      "Epoch 58/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0145 - mean_absolute_error: 0.0707 - val_loss: 0.4643 - val_mean_absolute_error: 0.4894\n",
      "Epoch 59/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0080 - mean_absolute_error: 0.0580 - val_loss: 0.4565 - val_mean_absolute_error: 0.4846\n",
      "Epoch 60/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0040 - mean_absolute_error: 0.0413 - val_loss: 0.4536 - val_mean_absolute_error: 0.4772\n",
      "Epoch 61/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0021 - mean_absolute_error: 0.0300 - val_loss: 0.4471 - val_mean_absolute_error: 0.4702\n",
      "Epoch 62/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0013 - mean_absolute_error: 0.0241 - val_loss: 0.4476 - val_mean_absolute_error: 0.4739\n",
      "Epoch 63/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 7.5778e-04 - mean_absolute_error: 0.0179 - val_loss: 0.4411 - val_mean_absolute_error: 0.4663\n",
      "Epoch 64/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.8033e-04 - mean_absolute_error: 0.0177 - val_loss: 0.4527 - val_mean_absolute_error: 0.4671\n",
      "Epoch 65/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 4.9513e-04 - mean_absolute_error: 0.0149 - val_loss: 0.4465 - val_mean_absolute_error: 0.4692\n",
      "Epoch 66/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 9.4401e-04 - mean_absolute_error: 0.0174 - val_loss: 0.4533 - val_mean_absolute_error: 0.4735\n",
      "Epoch 67/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 5.5736e-04 - mean_absolute_error: 0.0148 - val_loss: 0.4492 - val_mean_absolute_error: 0.4690\n",
      "Epoch 68/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 5.8796e-04 - mean_absolute_error: 0.0157 - val_loss: 0.4471 - val_mean_absolute_error: 0.4704\n",
      "Epoch 69/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.5668e-04 - mean_absolute_error: 0.0186 - val_loss: 0.4432 - val_mean_absolute_error: 0.4678\n",
      "Epoch 70/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 8.7746e-04 - mean_absolute_error: 0.0188 - val_loss: 0.4475 - val_mean_absolute_error: 0.4716\n",
      "Epoch 71/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 7.1232e-04 - mean_absolute_error: 0.0171 - val_loss: 0.4518 - val_mean_absolute_error: 0.4812\n",
      "Epoch 72/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0010 - mean_absolute_error: 0.0206 - val_loss: 0.4481 - val_mean_absolute_error: 0.4718\n",
      "Epoch 73/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 9.4316e-04 - mean_absolute_error: 0.0202 - val_loss: 0.4474 - val_mean_absolute_error: 0.4752\n",
      "Epoch 74/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 7.8397e-04 - mean_absolute_error: 0.0184 - val_loss: 0.4490 - val_mean_absolute_error: 0.4721\n",
      "Epoch 75/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0011 - mean_absolute_error: 0.0212 - val_loss: 0.4478 - val_mean_absolute_error: 0.4738\n",
      "Epoch 76/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0017 - mean_absolute_error: 0.0275 - val_loss: 0.4725 - val_mean_absolute_error: 0.4888\n",
      "Epoch 77/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0020 - mean_absolute_error: 0.0296 - val_loss: 0.4609 - val_mean_absolute_error: 0.4861\n",
      "Epoch 78/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0041 - mean_absolute_error: 0.0377 - val_loss: 0.4615 - val_mean_absolute_error: 0.4835\n",
      "Epoch 79/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0056 - mean_absolute_error: 0.0472 - val_loss: 0.4716 - val_mean_absolute_error: 0.4739\n",
      "Epoch 80/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0146 - mean_absolute_error: 0.0718 - val_loss: 0.4942 - val_mean_absolute_error: 0.4957\n",
      "Epoch 81/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0055 - mean_absolute_error: 0.0486 - val_loss: 0.4755 - val_mean_absolute_error: 0.4657\n",
      "Epoch 82/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0031 - mean_absolute_error: 0.0361 - val_loss: 0.4568 - val_mean_absolute_error: 0.4663\n",
      "Epoch 83/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0019 - mean_absolute_error: 0.0283 - val_loss: 0.4571 - val_mean_absolute_error: 0.4535\n",
      "Epoch 84/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 9.1124e-04 - mean_absolute_error: 0.0195 - val_loss: 0.4553 - val_mean_absolute_error: 0.4508\n",
      "Epoch 85/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 5.2933e-04 - mean_absolute_error: 0.0140 - val_loss: 0.4592 - val_mean_absolute_error: 0.4561\n",
      "Epoch 86/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3.3523e-04 - mean_absolute_error: 0.0117 - val_loss: 0.4504 - val_mean_absolute_error: 0.4479\n",
      "Epoch 87/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2.4323e-04 - mean_absolute_error: 0.0089 - val_loss: 0.4499 - val_mean_absolute_error: 0.4497\n",
      "Epoch 88/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 1.8985e-04 - mean_absolute_error: 0.0082 - val_loss: 0.4498 - val_mean_absolute_error: 0.4491\n",
      "Epoch 89/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2.0216e-04 - mean_absolute_error: 0.0087 - val_loss: 0.4532 - val_mean_absolute_error: 0.4503\n",
      "Epoch 90/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.3761e-04 - mean_absolute_error: 0.0072 - val_loss: 0.4482 - val_mean_absolute_error: 0.4501\n",
      "Epoch 91/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 1.5066e-04 - mean_absolute_error: 0.0075 - val_loss: 0.4572 - val_mean_absolute_error: 0.4530\n",
      "Epoch 92/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2.0947e-04 - mean_absolute_error: 0.0083 - val_loss: 0.4493 - val_mean_absolute_error: 0.4529\n",
      "Epoch 93/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 3.6430e-04 - mean_absolute_error: 0.0114 - val_loss: 0.4482 - val_mean_absolute_error: 0.4505\n",
      "Epoch 94/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 8.0837e-04 - mean_absolute_error: 0.0177 - val_loss: 0.4490 - val_mean_absolute_error: 0.4512\n",
      "Epoch 95/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 7.5302e-04 - mean_absolute_error: 0.0173 - val_loss: 0.4467 - val_mean_absolute_error: 0.4505\n",
      "Epoch 96/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 8.1204e-04 - mean_absolute_error: 0.0180 - val_loss: 0.4523 - val_mean_absolute_error: 0.4555\n",
      "Epoch 97/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0011 - mean_absolute_error: 0.0207 - val_loss: 0.4428 - val_mean_absolute_error: 0.4499\n",
      "Epoch 98/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 7.3522e-04 - mean_absolute_error: 0.0180 - val_loss: 0.4536 - val_mean_absolute_error: 0.4578\n",
      "Epoch 99/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 7.5863e-04 - mean_absolute_error: 0.0179 - val_loss: 0.4447 - val_mean_absolute_error: 0.4509\n",
      "Epoch 100/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 6.4743e-04 - mean_absolute_error: 0.0162 - val_loss: 0.4554 - val_mean_absolute_error: 0.4639\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "Mean Squared Error: 0.46300881931132837\n",
      "R² Score: 0.6385195851325989\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Đọc dữ liệu\n",
    "data = pd.read_csv('cleaned_hospitals.csv')\n",
    "\n",
    "# Kiểm tra các giá trị null\n",
    "if data.isnull().sum().any():\n",
    "    raise ValueError(\"Dữ liệu chứa giá trị null, vui lòng xử lý trước khi tiếp tục.\")\n",
    "\n",
    "# Chuẩn bị dữ liệu\n",
    "X = data.drop(columns=['Rating_Readmission'])\n",
    "y = data['Rating_Readmission']\n",
    "\n",
    "# Tách thành các loại dữ liệu\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Tạo biến chuyển đổi\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Kết hợp các biến chuyển đổi\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Chuyển đổi dữ liệu đầu vào qua preprocessor\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# Xác định số lượng đầu vào cho mô hình\n",
    "input_shape = X_train_processed.shape[1]  # Số lượng đặc trưng sau khi mã hóa\n",
    "\n",
    "# Xây dựng mô hình\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(input_shape,)),  # Số lượng đặc trưng\n",
    "    layers.Dense(128, activation='relu'),  # Tăng số nơ-ron\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # Đầu ra là một số thực\n",
    "])\n",
    "\n",
    "# Biên dịch mô hình\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# Thiết lập callback để lưu mô hình tốt nhất\n",
    "checkpoint_callback = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "history = model.fit(X_train_processed, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[checkpoint_callback])\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "y_pred = model.predict(X_test_processed)\n",
    "\n",
    "# Tính toán các chỉ số đánh giá\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R² Score: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d202245-d808-43ea-96c1-8053f3fb414f",
   "metadata": {},
   "source": [
    "# 4. Phân tích cụm (Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "764af443-9ef7-4089-ae79-2a2847ff46d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phân cụm hoàn tất và mô hình đã được lưu.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.exceptions import NotFittedError\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load data from a CSV file.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Tệp {file_path} không tồn tại.\")\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"Select numeric columns and scale the data.\"\"\"\n",
    "    numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "    if len(numeric_columns) == 0:\n",
    "        raise ValueError(\"Dữ liệu không có cột số nào để phân cụm.\")\n",
    "    return data[numeric_columns]\n",
    "\n",
    "def perform_clustering(X, n_clusters=3):\n",
    "    \"\"\"Perform KMeans clustering.\"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "    return clusters, kmeans\n",
    "\n",
    "def save_model(model, file_path):\n",
    "    \"\"\"Save the trained model.\"\"\"\n",
    "    joblib.dump(model, file_path)\n",
    "\n",
    "def save_results(data, file_path):\n",
    "    \"\"\"Save the DataFrame with clusters to a CSV file.\"\"\"\n",
    "    data.to_csv(file_path, index=False)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the clustering process.\"\"\"\n",
    "    input_file = 'cleaned_hospitals.csv'\n",
    "    output_file = 'clustered_hospitals.csv'\n",
    "    model_file = 'kmeans_model.joblib'\n",
    "    \n",
    "    try:\n",
    "        data = load_data(input_file)\n",
    "        X = preprocess_data(data)\n",
    "        \n",
    "        # Chọn số lượng cụm, có thể thay đổi\n",
    "        n_clusters = 3\n",
    "        \n",
    "        clusters, kmeans = perform_clustering(X, n_clusters)\n",
    "        \n",
    "        # Gán nhãn cụm vào DataFrame gốc\n",
    "        data['Cluster'] = clusters\n",
    "        \n",
    "        # Lưu mô hình KMeans\n",
    "        save_model(kmeans, model_file)\n",
    "        \n",
    "        # Lưu DataFrame với nhãn cụm\n",
    "        save_results(data, output_file)\n",
    "\n",
    "        print(\"Phân cụm hoàn tất và mô hình đã được lưu.\")\n",
    "    except (FileNotFoundError, ValueError) as e:\n",
    "        print(f\"Lỗi: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c284667-414d-48e1-9a14-2a96ec051473",
   "metadata": {},
   "source": [
    "# 5. Dự đoán chi phí (Cost Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c552acdd-ea4c-48a5-8cbf-7b78a9fd9609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4772 entries, 0 to 4771\n",
      "Data columns (total 24 columns):\n",
      " #   Column                           Non-Null Count  Dtype \n",
      "---  ------                           --------------  ----- \n",
      " 0   Facility_Name                    4772 non-null   object\n",
      " 1   Facility_City                    4772 non-null   object\n",
      " 2   Facility_State                   4772 non-null   object\n",
      " 3   Facility_Type                    4772 non-null   object\n",
      " 4   Rating_Overall                   4772 non-null   int64 \n",
      " 5   Rating_Mortality                 4772 non-null   int64 \n",
      " 6   Rating_Safety                    4772 non-null   int64 \n",
      " 7   Rating_Readmission               4772 non-null   int64 \n",
      " 8   Rating_Experience                4772 non-null   int64 \n",
      " 9   Rating_Effectiveness             4772 non-null   int64 \n",
      " 10  Rating_Timeliness                4772 non-null   int64 \n",
      " 11  Rating_Imaging                   4772 non-null   int64 \n",
      " 12  Procedure_Heart_Attack_Cost      4772 non-null   int64 \n",
      " 13  Procedure_Heart_Attack_Quality   4772 non-null   int64 \n",
      " 14  Procedure_Heart_Attack_Value     4772 non-null   object\n",
      " 15  Procedure_Heart_Failure_Cost     4772 non-null   int64 \n",
      " 16  Procedure_Heart_Failure_Quality  4772 non-null   int64 \n",
      " 17  Procedure_Heart_Failure_Value    4772 non-null   object\n",
      " 18  Procedure_Pneumonia_Cost         4772 non-null   int64 \n",
      " 19  Procedure_Pneumonia_Quality      4772 non-null   int64 \n",
      " 20  Procedure_Pneumonia_Value        4772 non-null   object\n",
      " 21  Procedure_Hip_Knee_Cost          4772 non-null   int64 \n",
      " 22  Procedure_Hip_Knee_Quality       4772 non-null   int64 \n",
      " 23  Procedure_Hip_Knee_Value         4772 non-null   object\n",
      "dtypes: int64(16), object(8)\n",
      "memory usage: 894.9+ KB\n",
      "None\n",
      "       Rating_Overall  Rating_Mortality  Rating_Safety  Rating_Readmission  \\\n",
      "count     4772.000000       4772.000000    4772.000000         4772.000000   \n",
      "mean         2.400880          2.053646       1.763412            1.272422   \n",
      "std          1.584358          0.825382       1.255121            1.098946   \n",
      "min          0.000000          0.000000       0.000000            0.000000   \n",
      "25%          1.000000          2.000000       1.000000            0.000000   \n",
      "50%          3.000000          2.000000       2.000000            1.000000   \n",
      "75%          4.000000          3.000000       3.000000            2.000000   \n",
      "max          5.000000          3.000000       3.000000            3.000000   \n",
      "\n",
      "       Rating_Experience  Rating_Effectiveness  Rating_Timeliness  \\\n",
      "count        4772.000000           4772.000000        4772.000000   \n",
      "mean            1.556999              2.067687           1.456622   \n",
      "std             1.141204              0.620535           1.098771   \n",
      "min             0.000000              0.000000           0.000000   \n",
      "25%             1.000000              2.000000           0.000000   \n",
      "50%             2.000000              2.000000           2.000000   \n",
      "75%             3.000000              2.000000           2.000000   \n",
      "max             3.000000              3.000000           3.000000   \n",
      "\n",
      "       Rating_Imaging  Procedure_Heart_Attack_Cost  \\\n",
      "count     4772.000000                  4772.000000   \n",
      "mean         2.081727                 11360.977997   \n",
      "std          0.905296                 11988.404171   \n",
      "min          0.000000                     0.000000   \n",
      "25%          2.000000                     0.000000   \n",
      "50%          2.000000                     0.000000   \n",
      "75%          3.000000                 23764.250000   \n",
      "max          3.000000                 29670.000000   \n",
      "\n",
      "       Procedure_Heart_Attack_Quality  Procedure_Heart_Failure_Cost  \\\n",
      "count                     4772.000000                   4772.000000   \n",
      "mean                         1.074811                  12149.034367   \n",
      "std                          1.000135                   7502.579223   \n",
      "min                          0.000000                      0.000000   \n",
      "25%                          0.000000                      0.000000   \n",
      "50%                          2.000000                  15921.500000   \n",
      "75%                          2.000000                  17126.500000   \n",
      "max                          3.000000                  22450.000000   \n",
      "\n",
      "       Procedure_Heart_Failure_Quality  Procedure_Pneumonia_Cost  \\\n",
      "count                      4772.000000               4772.000000   \n",
      "mean                          0.670788              14625.655071   \n",
      "std                           0.967271               6598.128266   \n",
      "min                           0.000000                  0.000000   \n",
      "25%                           0.000000              15169.500000   \n",
      "50%                           0.000000              16933.500000   \n",
      "75%                           2.000000              18245.000000   \n",
      "max                           3.000000              27126.000000   \n",
      "\n",
      "       Procedure_Pneumonia_Quality  Procedure_Hip_Knee_Cost  \\\n",
      "count                   4772.00000              4772.000000   \n",
      "mean                       0.51425             12501.068525   \n",
      "std                        0.93198             10997.181810   \n",
      "min                        0.00000                 0.000000   \n",
      "25%                        0.00000                 0.000000   \n",
      "50%                        0.00000             19120.000000   \n",
      "75%                        1.00000             21985.500000   \n",
      "max                        3.00000             42546.000000   \n",
      "\n",
      "       Procedure_Hip_Knee_Quality  \n",
      "count                 4772.000000  \n",
      "mean                     0.898994  \n",
      "std                      1.001708  \n",
      "min                      0.000000  \n",
      "25%                      0.000000  \n",
      "50%                      0.000000  \n",
      "75%                      2.000000  \n",
      "max                      3.000000  \n",
      "Kiểu dữ liệu của X_train: float64\n",
      "Kiểu dữ liệu của y_train: int64\n",
      "Epoch 1/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 284370528.0000 - val_loss: 254628304.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 159644736.0000 - val_loss: 180685328.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 57884480.0000 - val_loss: 173109760.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 43452924.0000 - val_loss: 165042960.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 31447424.0000 - val_loss: 155089664.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 21938484.0000 - val_loss: 147723680.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 13862155.0000 - val_loss: 141397616.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 11421545.0000 - val_loss: 138112256.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 7653395.0000 - val_loss: 135048928.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 6272300.0000 - val_loss: 133416992.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 4804883.0000 - val_loss: 131169512.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 4158712.0000 - val_loss: 130640728.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 4091627.7500 - val_loss: 130315376.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 3415642.0000 - val_loss: 129512528.0000\n",
      "Epoch 15/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2750071.0000 - val_loss: 129491008.0000\n",
      "Epoch 16/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 3342486.2500 - val_loss: 129443840.0000\n",
      "Epoch 17/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 2598062.5000 - val_loss: 128954368.0000\n",
      "Epoch 18/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2520594.0000 - val_loss: 128724240.0000\n",
      "Epoch 19/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 2436913.0000 - val_loss: 128955784.0000\n",
      "Epoch 20/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 2343176.5000 - val_loss: 129807304.0000\n",
      "Epoch 21/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2404214.2500 - val_loss: 130230648.0000\n",
      "Epoch 22/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 2021539.0000 - val_loss: 130335824.0000\n",
      "Epoch 23/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2152041.7500 - val_loss: 131797744.0000\n",
      "Epoch 24/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 2400877.0000 - val_loss: 132131896.0000\n",
      "Epoch 25/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 2261851.2500 - val_loss: 133768400.0000\n",
      "Epoch 26/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2098825.5000 - val_loss: 133172584.0000\n",
      "Epoch 27/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 2559377.0000 - val_loss: 134144432.0000\n",
      "Epoch 28/100\n",
      "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 2193035.0000 - val_loss: 135018256.0000\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 911265536.0000\n",
      "Model Test Loss: 912364800.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Đọc dữ liệu\n",
    "data = pd.read_csv('cleaned_hospitals.csv')\n",
    "\n",
    "# Kiểm tra kiểu dữ liệu và thông tin tổng quan về dữ liệu\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "\n",
    "# Chọn cột để dự đoán và loại bỏ cột không cần thiết\n",
    "X = data.drop(columns=['Procedure_Heart_Attack_Cost'])\n",
    "y = data['Procedure_Heart_Attack_Cost']\n",
    "\n",
    "# Chuyển đổi cột object và bool thành số (one-hot encoding)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Chuyển đổi cột y thành số (nếu chưa)\n",
    "y = pd.to_numeric(y, errors='coerce')\n",
    "\n",
    "# Xóa các hàng có giá trị NaN trong y và X\n",
    "X = X[y.notna()]\n",
    "y = y.dropna()\n",
    "\n",
    "# Kiểm tra lại sau khi loại bỏ NaN\n",
    "if X.empty or y.empty:\n",
    "    raise ValueError(\"Dữ liệu không đủ sau khi loại bỏ NaN!\")\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Kiểm tra lại kiểu dữ liệu\n",
    "print(\"Kiểu dữ liệu của X_train:\", X_train.dtype)\n",
    "print(\"Kiểu dữ liệu của y_train:\", y_train.dtype)\n",
    "\n",
    "# Xây dựng mô hình\n",
    "model = keras.Sequential([\n",
    "    layers.Input(shape=(X_train.shape[1],)),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.2),  # Dropout layer để giảm overfitting\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)  # Đầu ra là một số thực (chi phí)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Huấn luyện mô hình với EarlyStopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
    "\n",
    "# Đánh giá mô hình trên tập kiểm tra\n",
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print(f'Model Test Loss: {test_loss}')\n",
    "\n",
    "# Lưu mô hình\n",
    "model.save('cost_prediction.keras')\n",
    "\n",
    "# Vẽ biểu đồ quá trình huấn luyện\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Loss (Training)')\n",
    "plt.plot(history.history['val_loss'], label='Loss (Validation)')\n",
    "plt.title('Loss during training')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563ca460-19f8-44d0-afc2-2f08fff7c6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
